{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __CNN__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to use CNN(convolutional neural networks) for the task of guitar tablature estimation. The previous work of Andrew Wiggins and Youngmoo Kim showed that CNNs have shown promise for translating guitar audios to tabs, and the use of CNNs has also been explored for various other tasks within music information retrieval such as musical tempo estimation, key classification, singing voice detection, and instrument classification. It is proven that CNN is a powerful tool for the purpose of our study."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Import libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages \n",
    "\n",
    "#various\n",
    "import datetime\n",
    "import pathlib\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import warnings\n",
    "\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "\n",
    "#keras\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "RSEED = 42\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "# Check for Tensorflow version\n",
    "print(tf.__version__)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Define Input Shapes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of all our constants we use for our model \n",
    "\n",
    "FRAME_HEIGHT = 9\n",
    "FRAME_WIDTH = 192\n",
    "N_CLASSES = 21\n",
    "N_STRINGS = 6\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Tensorboard to monitor our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs/fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Load Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we load the data from our output folder from preprocessing\n",
    "INPUT_PATH = \"../data/output/\"\n",
    "save_path = \"../app/model/\"\n",
    "\n",
    "#for all\n",
    "# IMAGES = np.load(INPUT_PATH + 'training_data_all_75.npz')\n",
    "# annots = np.load(INPUT_PATH + 'training_labels_all_75.npz')\n",
    "\n",
    "\n",
    "# for solo  \n",
    "IMAGES = np.load(INPUT_PATH + '05_Rock3-117-Bb_solo_hex_cln_data_portrait.npz')\n",
    "annots = np.load(INPUT_PATH + '05_Rock3-117-Bb_solo_hex_cln_labels_portrait.npz')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Do train & test split__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we have to split our dataset into train and test set. We use 70% for the train set and 30% for the test set.\n",
    "train_images, test_images, train_annots, test_annots = train_test_split(IMAGES['arr_0'], annots['arr_0'], test_size= 0.2, shuffle=True, random_state= RSEED )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because we need also a validation set we split once more. We take this time 10% of the train set for \n",
    "#the validation set and take the rest for training.\n",
    "train_images, validate_images,train_annots,validate_annots = train_test_split(train_images, train_annots, test_size = 0.1, shuffle=True, random_state = RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 9, 192)\n",
      "(127, 9, 192)\n",
      "(51, 9, 192)\n",
      "(455, 6, 21)\n",
      "(127, 6, 21)\n",
      "(51, 6, 21)\n"
     ]
    }
   ],
   "source": [
    "#let's have a look on the different shapes of our sets\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(validate_images.shape)\n",
    "print(train_annots.shape)\n",
    "print(test_annots.shape)\n",
    "print(validate_annots.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Define our softmax function by string__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_by_string(t):\n",
    "        sh = K.shape(t)\n",
    "        string_sm = []\n",
    "        for i in range(N_STRINGS):\n",
    "            string_sm.append(K.expand_dims(K.softmax(t[:,i,:]), axis=1))\n",
    "        return K.concatenate(string_sm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catcross_by_string(target, output):\n",
    "        loss = 0\n",
    "        for i in range(N_STRINGS):\n",
    "            loss += K.categorical_crossentropy(target[:,i,:], output[:,i,:])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_acc(y_true, y_pred):\n",
    "        return K.mean(K.equal(K.argmax(y_true, axis=-1), K.argmax(y_pred, axis=-1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Building our CNN Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function of our cnn model\n",
    "'''what it takes:\n",
    "- a picture with a certain frame height(192pixel) and a frame width(9 pixel)\n",
    "- only one color channel, therefore as a grayscale image\n",
    "\n",
    "what it deliver:\n",
    "\n",
    "An array with the size 6x21. This is representing the 6 different strings of a guitar and 19 different \n",
    "frets of the guitar. The other 2 of the 21 entries represent, if a string is played or not played.\n",
    "\n",
    "The different layers we used you can easily extract from below.\n",
    "'''\n",
    "\n",
    "def cnn_swizzle_model():       \n",
    "        swizzle_model = tf.keras.Sequential()\n",
    "        swizzle_model.add(tf.keras.layers.InputLayer(input_shape=[FRAME_HEIGHT, FRAME_WIDTH, 1]))\n",
    "        swizzle_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3),activation='relu'))\n",
    "        swizzle_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "        swizzle_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "        swizzle_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        swizzle_model.add(tf.keras.layers.Dropout(0.25))   \n",
    "        swizzle_model.add(tf.keras.layers.Flatten())\n",
    "        swizzle_model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        swizzle_model.add(tf.keras.layers.Dropout(0.5))\n",
    "        swizzle_model.add(tf.keras.layers.Dense(N_CLASSES * N_STRINGS))\n",
    "        swizzle_model.add(tf.keras.layers.Reshape((N_STRINGS, N_CLASSES)))\n",
    "        swizzle_model.add(tf.keras.layers.Activation(softmax_by_string))\n",
    "        return swizzle_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 11:46:25.218983: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-17 11:46:25.219342: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#this is our swizzle model\n",
    "swizzle_model = cnn_swizzle_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 7, 190, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 5, 188, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 186, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, 93, 64)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 93, 64)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5952)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               761984    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 126)               16254     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 6, 21)             0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 6, 21)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 833,982\n",
      "Trainable params: 833,982\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#let's have a look on the model summary to see the different layers and their shapes\n",
    "#we have 3 dimensions in the beginning, then flatten to 1 Dimension for the dense layers and after them\n",
    "#create the end shape representing the guitar with 6 strings and 21 frets\n",
    "swizzle_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model metrics for the cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Metric: For our model we will use the accuracy metric, because we want to have o good overall \n",
    "prediction of our model. Besides that, for us every tone has the same importance so all classes\n",
    "have the same importance.\n",
    "\n",
    "Optimizer: As an optimizer we take the adam optimizer, which is fast enough to handle our data \n",
    "in a short time\n",
    "\n",
    "Loss function: For the loss function we used categorical crossentropy because we have multiple classes or labels\n",
    "with soft probabilities like [0.5, 0.3, 0.2] and also have a shape like a one-hot-encoded array.\n",
    "'''\n",
    "\n",
    "metrics = avg_acc\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adadelta(learning_rate=1.0)\n",
    "\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "swizzle_model.compile(loss=catcross_by_string, optimizer=optimizer, metrics= metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use annealer to decrease learning rate after given epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "'''\n",
    "With the ReduceLROnPlateau function from Keras.callbacks, \n",
    "we choose to reduce the Learning Rate by half if the accuracy is not improved after 3 epochs.\n",
    "'''\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Train CNN__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folder for model \n",
    "'''This function takes the path of a new folder and create a new one. \n",
    "If the folder already exists, it will pass.'''\n",
    "def my_makedirs(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "my_makedirs('../app/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = tf.keras.callbacks.CSVLogger('../data/model/metrics_op.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 11:46:25.594255: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-01-17 11:46:26.292345: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - ETA: 0s - loss: 15.3401 - avg_acc: 0.4845"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 11:46:27.955547: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 277ms/step - loss: 15.3401 - avg_acc: 0.4845 - val_loss: 4.7717 - val_avg_acc: 0.8660\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 6.0146 - avg_acc: 0.7905 - val_loss: 3.5734 - val_avg_acc: 0.8791\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 4.2164 - avg_acc: 0.8379 - val_loss: 2.2639 - val_avg_acc: 0.8889\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 2.8567 - avg_acc: 0.8733 - val_loss: 1.8075 - val_avg_acc: 0.8987\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.1999 - avg_acc: 0.8612 - val_loss: 1.6776 - val_avg_acc: 0.9020\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 2.4983 - avg_acc: 0.8813 - val_loss: 1.6032 - val_avg_acc: 0.9118\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 1.6619 - avg_acc: 0.9136 - val_loss: 1.3640 - val_avg_acc: 0.9183\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.7126 - avg_acc: 0.9109 - val_loss: 1.2854 - val_avg_acc: 0.9183\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 1.3171 - avg_acc: 0.9303 - val_loss: 1.0537 - val_avg_acc: 0.9477\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 1.1748 - avg_acc: 0.9333 - val_loss: 0.8420 - val_avg_acc: 0.9412\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.0652 - avg_acc: 0.9370 - val_loss: 0.7185 - val_avg_acc: 0.9575\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.1357 - avg_acc: 0.9313 - val_loss: 0.7320 - val_avg_acc: 0.9706\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.8069 - avg_acc: 0.9550 - val_loss: 0.6423 - val_avg_acc: 0.9542\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.7808 - avg_acc: 0.9521 - val_loss: 0.9635 - val_avg_acc: 0.9346\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.9080 - avg_acc: 0.9539 - val_loss: 0.6066 - val_avg_acc: 0.9673\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.7315 - avg_acc: 0.9535 - val_loss: 0.7135 - val_avg_acc: 0.9641\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.7032 - avg_acc: 0.9595 - val_loss: 0.4783 - val_avg_acc: 0.9706\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.6235 - avg_acc: 0.9681 - val_loss: 0.3186 - val_avg_acc: 0.9837\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4097 - avg_acc: 0.9723 - val_loss: 0.3985 - val_avg_acc: 0.9739\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4452 - avg_acc: 0.9753 - val_loss: 0.2419 - val_avg_acc: 0.9804\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4393 - avg_acc: 0.9751 - val_loss: 0.2355 - val_avg_acc: 0.9804\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.3887 - avg_acc: 0.9784 - val_loss: 0.2697 - val_avg_acc: 0.9837\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3653 - avg_acc: 0.9759 - val_loss: 0.1698 - val_avg_acc: 0.9902\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.4979 - avg_acc: 0.9682 - val_loss: 0.1995 - val_avg_acc: 0.9869\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3167 - avg_acc: 0.9812 - val_loss: 0.2395 - val_avg_acc: 0.9935\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3718 - avg_acc: 0.9715 - val_loss: 0.3500 - val_avg_acc: 0.9837\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4212 - avg_acc: 0.9784 - val_loss: 0.3745 - val_avg_acc: 0.9869\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3094 - avg_acc: 0.9813 - val_loss: 0.1672 - val_avg_acc: 0.9902\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2848 - avg_acc: 0.9843 - val_loss: 0.2553 - val_avg_acc: 0.9935\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2886 - avg_acc: 0.9822 - val_loss: 0.1066 - val_avg_acc: 0.9935\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2194 - avg_acc: 0.9895 - val_loss: 0.1084 - val_avg_acc: 0.9935\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1990 - avg_acc: 0.9881 - val_loss: 0.2327 - val_avg_acc: 0.9869\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2509 - avg_acc: 0.9857 - val_loss: 0.2224 - val_avg_acc: 0.9902\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 0.2095 - avg_acc: 0.9883 - val_loss: 0.0806 - val_avg_acc: 0.9935\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.2049 - avg_acc: 0.9867 - val_loss: 0.1302 - val_avg_acc: 0.9935\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2149 - avg_acc: 0.9842 - val_loss: 0.1675 - val_avg_acc: 0.9902\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2470 - avg_acc: 0.9875 - val_loss: 0.1042 - val_avg_acc: 0.9967\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.2180 - avg_acc: 0.9881 - val_loss: 0.1914 - val_avg_acc: 0.9869\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 0.2043 - avg_acc: 0.9879 - val_loss: 0.0961 - val_avg_acc: 0.9935\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1942 - avg_acc: 0.9896 - val_loss: 0.2086 - val_avg_acc: 0.9935\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.1919 - avg_acc: 0.9895 - val_loss: 0.1878 - val_avg_acc: 0.9902\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1671 - avg_acc: 0.9930 - val_loss: 0.1040 - val_avg_acc: 0.9967\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1051 - avg_acc: 0.9919 - val_loss: 0.2745 - val_avg_acc: 0.9902\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 0.1207 - avg_acc: 0.9934 - val_loss: 0.1415 - val_avg_acc: 0.9935\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.1238 - avg_acc: 0.9915 - val_loss: 0.0718 - val_avg_acc: 0.9935\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1343 - avg_acc: 0.9911 - val_loss: 0.1378 - val_avg_acc: 0.9967\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1729 - avg_acc: 0.9913 - val_loss: 0.0980 - val_avg_acc: 0.9902\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.1337 - avg_acc: 0.9924 - val_loss: 0.0551 - val_avg_acc: 0.9935\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.1347 - avg_acc: 0.9918 - val_loss: 0.1183 - val_avg_acc: 0.9935\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1797 - avg_acc: 0.9890 - val_loss: 0.0935 - val_avg_acc: 0.9902\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1427 - avg_acc: 0.9921 - val_loss: 0.1929 - val_avg_acc: 0.9902\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1243 - avg_acc: 0.9934 - val_loss: 0.0567 - val_avg_acc: 0.9935\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1116 - avg_acc: 0.9923 - val_loss: 0.2795 - val_avg_acc: 0.9902\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1783 - avg_acc: 0.9936 - val_loss: 0.0746 - val_avg_acc: 0.9967\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 0.1064 - avg_acc: 0.9941 - val_loss: 0.0881 - val_avg_acc: 0.9902\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.1026 - avg_acc: 0.9935 - val_loss: 0.1556 - val_avg_acc: 0.9935\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1665 - avg_acc: 0.9917 - val_loss: 0.0627 - val_avg_acc: 0.9967\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0998 - avg_acc: 0.9947 - val_loss: 0.1433 - val_avg_acc: 0.9967\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1201 - avg_acc: 0.9917 - val_loss: 0.0850 - val_avg_acc: 0.9935\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0884 - avg_acc: 0.9939 - val_loss: 0.1270 - val_avg_acc: 0.9902\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0687 - avg_acc: 0.9960 - val_loss: 0.1385 - val_avg_acc: 0.9935\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1117 - avg_acc: 0.9925 - val_loss: 0.2030 - val_avg_acc: 0.9935\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1133 - avg_acc: 0.9930 - val_loss: 0.2044 - val_avg_acc: 0.9902\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0762 - avg_acc: 0.9956 - val_loss: 0.0843 - val_avg_acc: 0.9935\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0611 - avg_acc: 0.9967 - val_loss: 0.1123 - val_avg_acc: 0.9935\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0453 - avg_acc: 0.9984 - val_loss: 0.1429 - val_avg_acc: 0.9935\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0477 - avg_acc: 0.9965 - val_loss: 0.0696 - val_avg_acc: 0.9967\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0606 - avg_acc: 0.9967 - val_loss: 0.1066 - val_avg_acc: 0.9935\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0389 - avg_acc: 0.9984 - val_loss: 0.1274 - val_avg_acc: 0.9902\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1335 - avg_acc: 0.9920 - val_loss: 0.3716 - val_avg_acc: 0.9935\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1193 - avg_acc: 0.9930 - val_loss: 0.1300 - val_avg_acc: 0.9935\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0737 - avg_acc: 0.9974 - val_loss: 0.0751 - val_avg_acc: 0.9935\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0461 - avg_acc: 0.9978 - val_loss: 0.1237 - val_avg_acc: 0.9935\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0915 - avg_acc: 0.9943 - val_loss: 0.1467 - val_avg_acc: 0.9935\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0531 - avg_acc: 0.9981 - val_loss: 0.1259 - val_avg_acc: 0.9935\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0408 - avg_acc: 0.9978 - val_loss: 0.0548 - val_avg_acc: 0.9935\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0448 - avg_acc: 0.9966 - val_loss: 0.2434 - val_avg_acc: 0.9902\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0567 - avg_acc: 0.9965 - val_loss: 0.0486 - val_avg_acc: 0.9935\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0462 - avg_acc: 0.9972 - val_loss: 0.1447 - val_avg_acc: 0.9902\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0365 - avg_acc: 0.9982 - val_loss: 0.2005 - val_avg_acc: 0.9902\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0532 - avg_acc: 0.9967 - val_loss: 0.0992 - val_avg_acc: 0.9967\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0385 - avg_acc: 0.9975 - val_loss: 0.1090 - val_avg_acc: 0.9935\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0553 - avg_acc: 0.9963 - val_loss: 0.2015 - val_avg_acc: 0.9935\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0619 - avg_acc: 0.9962 - val_loss: 0.0925 - val_avg_acc: 0.9935\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0446 - avg_acc: 0.9965 - val_loss: 0.0663 - val_avg_acc: 0.9967\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0316 - avg_acc: 0.9990 - val_loss: 0.1099 - val_avg_acc: 0.9935\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0313 - avg_acc: 0.9978 - val_loss: 0.1359 - val_avg_acc: 0.9902\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0194 - avg_acc: 0.9997 - val_loss: 0.1196 - val_avg_acc: 0.9902\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0347 - avg_acc: 0.9973 - val_loss: 0.1678 - val_avg_acc: 0.9935\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0451 - avg_acc: 0.9975 - val_loss: 0.1288 - val_avg_acc: 0.9902\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0283 - avg_acc: 0.9984 - val_loss: 0.1313 - val_avg_acc: 0.9902\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0203 - avg_acc: 0.9991 - val_loss: 0.1432 - val_avg_acc: 0.9935\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0363 - avg_acc: 0.9984 - val_loss: 0.2220 - val_avg_acc: 0.9902\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0504 - avg_acc: 0.9974 - val_loss: 0.0927 - val_avg_acc: 0.9967\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1144 - avg_acc: 0.9919 - val_loss: 0.1180 - val_avg_acc: 0.9935\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0598 - avg_acc: 0.9962 - val_loss: 0.0303 - val_avg_acc: 0.9967\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0755 - avg_acc: 0.9964 - val_loss: 0.1146 - val_avg_acc: 0.9967\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0380 - avg_acc: 0.9975 - val_loss: 0.0699 - val_avg_acc: 0.9935\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0488 - avg_acc: 0.9969 - val_loss: 0.0844 - val_avg_acc: 0.9902\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0302 - avg_acc: 0.9987 - val_loss: 0.0659 - val_avg_acc: 0.9935\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0304 - avg_acc: 0.9975 - val_loss: 0.0701 - val_avg_acc: 0.9967\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0290 - avg_acc: 0.9978 - val_loss: 0.1072 - val_avg_acc: 0.9935\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0686 - avg_acc: 0.9968 - val_loss: 0.0232 - val_avg_acc: 1.0000\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0514 - avg_acc: 0.9984 - val_loss: 0.0946 - val_avg_acc: 0.9935\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0157 - avg_acc: 0.9997 - val_loss: 0.0981 - val_avg_acc: 0.9935\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0229 - avg_acc: 0.9993 - val_loss: 0.1375 - val_avg_acc: 0.9935\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0222 - avg_acc: 0.9991 - val_loss: 0.1141 - val_avg_acc: 0.9935\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0141 - avg_acc: 1.0000 - val_loss: 0.0580 - val_avg_acc: 0.9935\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0192 - avg_acc: 0.9997 - val_loss: 0.0456 - val_avg_acc: 0.9935\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0131 - avg_acc: 1.0000 - val_loss: 0.0474 - val_avg_acc: 0.9935\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0176 - avg_acc: 0.9990 - val_loss: 0.1606 - val_avg_acc: 0.9902\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0657 - avg_acc: 0.9951 - val_loss: 0.2391 - val_avg_acc: 0.9935\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0262 - avg_acc: 0.9982 - val_loss: 0.0828 - val_avg_acc: 0.9935\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0142 - avg_acc: 0.9994 - val_loss: 0.1377 - val_avg_acc: 0.9935\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0175 - avg_acc: 0.9991 - val_loss: 0.2094 - val_avg_acc: 0.9935\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0203 - avg_acc: 0.9990 - val_loss: 0.1396 - val_avg_acc: 0.9902\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0166 - avg_acc: 0.9987 - val_loss: 0.0985 - val_avg_acc: 0.9902\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0165 - avg_acc: 0.9991 - val_loss: 0.1795 - val_avg_acc: 0.9902\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0227 - avg_acc: 0.9988 - val_loss: 0.1634 - val_avg_acc: 0.9935\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0214 - avg_acc: 0.9991 - val_loss: 0.1671 - val_avg_acc: 0.9935\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0200 - avg_acc: 0.9990 - val_loss: 0.0908 - val_avg_acc: 0.9902\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0280 - avg_acc: 0.9993 - val_loss: 0.0487 - val_avg_acc: 0.9967\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0166 - avg_acc: 0.9997 - val_loss: 0.1033 - val_avg_acc: 0.9902\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0337 - avg_acc: 0.9981 - val_loss: 0.1614 - val_avg_acc: 0.9902\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0257 - avg_acc: 0.9978 - val_loss: 0.1036 - val_avg_acc: 0.9902\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0166 - avg_acc: 0.9991 - val_loss: 0.0732 - val_avg_acc: 0.9935\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0297 - avg_acc: 0.9972 - val_loss: 0.0458 - val_avg_acc: 0.9935\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0249 - avg_acc: 0.9987 - val_loss: 0.0816 - val_avg_acc: 0.9935\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 0.0178 - avg_acc: 0.9987 - val_loss: 0.0834 - val_avg_acc: 0.9935\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0165 - avg_acc: 0.9991 - val_loss: 0.0837 - val_avg_acc: 0.9935\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0179 - avg_acc: 0.9990 - val_loss: 0.1054 - val_avg_acc: 0.9902\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0083 - avg_acc: 0.9997 - val_loss: 0.0904 - val_avg_acc: 0.9935\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0282 - avg_acc: 0.9979 - val_loss: 0.1411 - val_avg_acc: 0.9902\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0188 - avg_acc: 0.9988 - val_loss: 0.0560 - val_avg_acc: 0.9935\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.0418 - avg_acc: 0.9975 - val_loss: 0.0654 - val_avg_acc: 0.9935\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0187 - avg_acc: 0.9988 - val_loss: 0.0804 - val_avg_acc: 0.9935\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0208 - avg_acc: 0.9990 - val_loss: 0.2650 - val_avg_acc: 0.9967\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0220 - avg_acc: 0.9987 - val_loss: 0.1106 - val_avg_acc: 0.9935\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0240 - avg_acc: 0.9984 - val_loss: 0.1598 - val_avg_acc: 0.9967\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0444 - avg_acc: 0.9971 - val_loss: 0.1892 - val_avg_acc: 0.9935\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.0178 - avg_acc: 0.9993 - val_loss: 0.2024 - val_avg_acc: 0.9935\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0212 - avg_acc: 0.9980 - val_loss: 0.1736 - val_avg_acc: 0.9935\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0111 - avg_acc: 0.9997 - val_loss: 0.1531 - val_avg_acc: 0.9902\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0110 - avg_acc: 0.9993 - val_loss: 0.1059 - val_avg_acc: 0.9902\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0264 - avg_acc: 0.9982 - val_loss: 0.2715 - val_avg_acc: 0.9935\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0308 - avg_acc: 0.9984 - val_loss: 0.1329 - val_avg_acc: 0.9935\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0172 - avg_acc: 0.9982 - val_loss: 0.0656 - val_avg_acc: 0.9935\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0122 - avg_acc: 0.9997 - val_loss: 0.1450 - val_avg_acc: 0.9935\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0104 - avg_acc: 0.9997 - val_loss: 0.0913 - val_avg_acc: 0.9902\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0258 - avg_acc: 0.9988 - val_loss: 0.0693 - val_avg_acc: 0.9967\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0238 - avg_acc: 0.9984 - val_loss: 0.3733 - val_avg_acc: 0.9902\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0543 - avg_acc: 0.9975 - val_loss: 0.1604 - val_avg_acc: 0.9935\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0287 - avg_acc: 0.9984 - val_loss: 0.1067 - val_avg_acc: 0.9902\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0138 - avg_acc: 0.9993 - val_loss: 0.0913 - val_avg_acc: 0.9902\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0096 - avg_acc: 0.9997 - val_loss: 0.1140 - val_avg_acc: 0.9935\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0303 - avg_acc: 0.9990 - val_loss: 0.1622 - val_avg_acc: 0.9902\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0125 - avg_acc: 0.9993 - val_loss: 0.1014 - val_avg_acc: 0.9902\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0213 - avg_acc: 0.9978 - val_loss: 0.0440 - val_avg_acc: 0.9967\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.0181 - avg_acc: 0.9987 - val_loss: 0.0876 - val_avg_acc: 0.9902\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0073 - avg_acc: 1.0000 - val_loss: 0.1485 - val_avg_acc: 0.9902\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0088 - avg_acc: 0.9994 - val_loss: 0.1232 - val_avg_acc: 0.9935\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0196 - avg_acc: 0.9991 - val_loss: 0.1259 - val_avg_acc: 0.9935\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0277 - avg_acc: 0.9978 - val_loss: 0.1610 - val_avg_acc: 0.9935\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0099 - avg_acc: 0.9997 - val_loss: 0.0537 - val_avg_acc: 0.9935\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0125 - avg_acc: 0.9988 - val_loss: 0.0419 - val_avg_acc: 0.9967\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0115 - avg_acc: 0.9997 - val_loss: 0.0986 - val_avg_acc: 0.9902\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0061 - avg_acc: 1.0000 - val_loss: 0.1265 - val_avg_acc: 0.9902\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0073 - avg_acc: 1.0000 - val_loss: 0.1244 - val_avg_acc: 0.9967\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0067 - avg_acc: 1.0000 - val_loss: 0.1086 - val_avg_acc: 0.9935\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0136 - avg_acc: 0.9993 - val_loss: 0.1073 - val_avg_acc: 0.9967\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0283 - avg_acc: 0.9978 - val_loss: 0.2350 - val_avg_acc: 0.9967\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0313 - avg_acc: 0.9984 - val_loss: 0.2604 - val_avg_acc: 0.9902\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0137 - avg_acc: 0.9990 - val_loss: 0.2291 - val_avg_acc: 0.9902\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0035 - avg_acc: 1.0000 - val_loss: 0.1594 - val_avg_acc: 0.9902\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0090 - avg_acc: 0.9994 - val_loss: 0.1840 - val_avg_acc: 0.9902\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 0.0043 - avg_acc: 1.0000 - val_loss: 0.1480 - val_avg_acc: 0.9902\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0070 - avg_acc: 0.9994 - val_loss: 0.1387 - val_avg_acc: 0.9935\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0077 - avg_acc: 0.9997 - val_loss: 0.1072 - val_avg_acc: 0.9902\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0093 - avg_acc: 0.9994 - val_loss: 0.1518 - val_avg_acc: 0.9902\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0136 - avg_acc: 0.9985 - val_loss: 0.1550 - val_avg_acc: 0.9935\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0113 - avg_acc: 0.9993 - val_loss: 0.1304 - val_avg_acc: 0.9935\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0099 - avg_acc: 0.9997 - val_loss: 0.2130 - val_avg_acc: 0.9902\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0124 - avg_acc: 0.9990 - val_loss: 0.1992 - val_avg_acc: 0.9902\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0095 - avg_acc: 0.9994 - val_loss: 0.2575 - val_avg_acc: 0.9902\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0110 - avg_acc: 0.9993 - val_loss: 0.1352 - val_avg_acc: 0.9935\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.0098 - avg_acc: 0.9997 - val_loss: 0.1766 - val_avg_acc: 0.9902\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.0107 - avg_acc: 0.9997 - val_loss: 0.2137 - val_avg_acc: 0.9902\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.0088 - avg_acc: 0.9997 - val_loss: 0.1428 - val_avg_acc: 0.9902\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0212 - avg_acc: 0.9994 - val_loss: 0.0545 - val_avg_acc: 0.9935\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1048 - avg_acc: 0.9951 - val_loss: 0.4693 - val_avg_acc: 0.9935\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1256 - avg_acc: 0.9962 - val_loss: 0.1974 - val_avg_acc: 0.9902\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0323 - avg_acc: 0.9975 - val_loss: 0.2168 - val_avg_acc: 0.9935\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0270 - avg_acc: 0.9978 - val_loss: 0.1962 - val_avg_acc: 0.9935\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0257 - avg_acc: 0.9981 - val_loss: 0.1759 - val_avg_acc: 0.9935\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0047 - avg_acc: 1.0000 - val_loss: 0.1267 - val_avg_acc: 0.9935\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0066 - avg_acc: 0.9994 - val_loss: 0.1125 - val_avg_acc: 0.9967\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0118 - avg_acc: 0.9994 - val_loss: 0.1269 - val_avg_acc: 0.9935\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.0102 - avg_acc: 0.9997 - val_loss: 0.1687 - val_avg_acc: 0.9902\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.0063 - avg_acc: 1.0000 - val_loss: 0.1069 - val_avg_acc: 0.9935\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.0073 - avg_acc: 0.9997 - val_loss: 0.1472 - val_avg_acc: 0.9902\n",
      "|     |   epoch |   avg_acc |        loss |   val_avg_acc |   val_loss |\n",
      "|----:|--------:|----------:|------------:|--------------:|-----------:|\n",
      "|   0 |       0 |  0.484476 | 15.3401     |      0.866013 |  4.77174   |\n",
      "|   1 |       1 |  0.790465 |  6.01456    |      0.879085 |  3.57339   |\n",
      "|   2 |       2 |  0.837904 |  4.21636    |      0.888889 |  2.26393   |\n",
      "|   3 |       3 |  0.873331 |  2.85668    |      0.898693 |  1.80749   |\n",
      "|   4 |       4 |  0.861204 |  3.19994    |      0.901961 |  1.67758   |\n",
      "|   5 |       5 |  0.881272 |  2.49829    |      0.911765 |  1.6032    |\n",
      "|   6 |       6 |  0.913572 |  1.66188    |      0.918301 |  1.36403   |\n",
      "|   7 |       7 |  0.910908 |  1.71259    |      0.918301 |  1.28542   |\n",
      "|   8 |       8 |  0.930316 |  1.31708    |      0.947712 |  1.05374   |\n",
      "|   9 |       9 |  0.93331  |  1.1748     |      0.941176 |  0.841955  |\n",
      "|  10 |      10 |  0.936954 |  1.06523    |      0.957516 |  0.718503  |\n",
      "|  11 |      11 |  0.931288 |  1.13575    |      0.970588 |  0.732042  |\n",
      "|  12 |      12 |  0.954996 |  0.806877   |      0.954248 |  0.642263  |\n",
      "|  13 |      13 |  0.95213  |  0.780842   |      0.934641 |  0.963477  |\n",
      "|  14 |      14 |  0.953891 |  0.90803    |      0.96732  |  0.606575  |\n",
      "|  15 |      15 |  0.953496 |  0.731529   |      0.964052 |  0.713537  |\n",
      "|  16 |      16 |  0.959489 |  0.703151   |      0.970588 |  0.478253  |\n",
      "|  17 |      17 |  0.96809  |  0.623478   |      0.98366  |  0.318567  |\n",
      "|  18 |      18 |  0.972253 |  0.409692   |      0.973856 |  0.398535  |\n",
      "|  19 |      19 |  0.975256 |  0.445174   |      0.980392 |  0.241925  |\n",
      "|  20 |      20 |  0.975118 |  0.439255   |      0.980392 |  0.235525  |\n",
      "|  21 |      21 |  0.978447 |  0.388696   |      0.98366  |  0.269717  |\n",
      "|  22 |      22 |  0.975902 |  0.365289   |      0.990196 |  0.169772  |\n",
      "|  23 |      23 |  0.968214 |  0.497898   |      0.986928 |  0.199489  |\n",
      "|  24 |      24 |  0.981179 |  0.316687   |      0.993464 |  0.239536  |\n",
      "|  25 |      25 |  0.971464 |  0.371808   |      0.98366  |  0.350006  |\n",
      "|  26 |      26 |  0.978374 |  0.421236   |      0.986928 |  0.3745    |\n",
      "|  27 |      27 |  0.981303 |  0.309419   |      0.990196 |  0.167163  |\n",
      "|  28 |      28 |  0.984306 |  0.284795   |      0.993464 |  0.25529   |\n",
      "|  29 |      29 |  0.982216 |  0.288602   |      0.993464 |  0.106585  |\n",
      "|  30 |      30 |  0.989515 |  0.219383   |      0.993464 |  0.108356  |\n",
      "|  31 |      31 |  0.988144 |  0.199003   |      0.986928 |  0.232683  |\n",
      "|  32 |      32 |  0.985673 |  0.250888   |      0.990196 |  0.222446  |\n",
      "|  33 |      33 |  0.988277 |  0.209523   |      0.993464 |  0.0806356 |\n",
      "|  34 |      34 |  0.986713 |  0.204902   |      0.993464 |  0.13023   |\n",
      "|  35 |      35 |  0.984233 |  0.214904   |      0.990196 |  0.167494  |\n",
      "|  36 |      36 |  0.987497 |  0.247011   |      0.996732 |  0.104201  |\n",
      "|  37 |      37 |  0.98808  |  0.218007   |      0.986928 |  0.191377  |\n",
      "|  38 |      38 |  0.987887 |  0.204292   |      0.993464 |  0.0961138 |\n",
      "|  39 |      39 |  0.989643 |  0.194238   |      0.993464 |  0.208605  |\n",
      "|  40 |      40 |  0.989515 |  0.191936   |      0.990196 |  0.187814  |\n",
      "|  41 |      41 |  0.992967 |  0.167146   |      0.996732 |  0.104016  |\n",
      "|  42 |      42 |  0.991857 |  0.105057   |      0.990196 |  0.274546  |\n",
      "|  43 |      43 |  0.993357 |  0.120703   |      0.993464 |  0.141531  |\n",
      "|  44 |      44 |  0.991532 |  0.123811   |      0.993464 |  0.0717938 |\n",
      "|  45 |      45 |  0.991073 |  0.13433    |      0.996732 |  0.13777   |\n",
      "|  46 |      46 |  0.991339 |  0.172869   |      0.990196 |  0.0980217 |\n",
      "|  47 |      47 |  0.99238  |  0.133717   |      0.993464 |  0.0550532 |\n",
      "|  48 |      48 |  0.991793 |  0.134708   |      0.993464 |  0.118331  |\n",
      "|  49 |      49 |  0.988992 |  0.179724   |      0.990196 |  0.0934542 |\n",
      "|  50 |      50 |  0.992055 |  0.142683   |      0.990196 |  0.192878  |\n",
      "|  51 |      51 |  0.993357 |  0.124321   |      0.993464 |  0.0566883 |\n",
      "|  52 |      52 |  0.992311 |  0.111645   |      0.990196 |  0.279458  |\n",
      "|  53 |      53 |  0.993618 |  0.178287   |      0.996732 |  0.0746166 |\n",
      "|  54 |      54 |  0.994141 |  0.106373   |      0.990196 |  0.0881311 |\n",
      "|  55 |      55 |  0.993485 |  0.102642   |      0.993464 |  0.155574  |\n",
      "|  56 |      56 |  0.991729 |  0.166545   |      0.996732 |  0.0626503 |\n",
      "|  57 |      57 |  0.994659 |  0.0998421  |      0.996732 |  0.143285  |\n",
      "|  58 |      58 |  0.991729 |  0.120096   |      0.993464 |  0.0850038 |\n",
      "|  59 |      59 |  0.993943 |  0.0883739  |      0.990196 |  0.126971  |\n",
      "|  60 |      60 |  0.996025 |  0.0687276  |      0.993464 |  0.138489  |\n",
      "|  61 |      61 |  0.992508 |  0.111725   |      0.993464 |  0.202961  |\n",
      "|  62 |      62 |  0.993031 |  0.113339   |      0.990196 |  0.204365  |\n",
      "|  63 |      63 |  0.995571 |  0.0762442  |      0.993464 |  0.0843116 |\n",
      "|  64 |      64 |  0.996745 |  0.0610917  |      0.993464 |  0.112343  |\n",
      "|  65 |      65 |  0.998372 |  0.0452754  |      0.993464 |  0.142909  |\n",
      "|  66 |      66 |  0.996548 |  0.0477172  |      0.996732 |  0.0695621 |\n",
      "|  67 |      67 |  0.996745 |  0.0605686  |      0.993464 |  0.106593  |\n",
      "|  68 |      68 |  0.998372 |  0.0388583  |      0.990196 |  0.127404  |\n",
      "|  69 |      69 |  0.991986 |  0.133548   |      0.993464 |  0.371637  |\n",
      "|  70 |      70 |  0.992967 |  0.119283   |      0.993464 |  0.130021  |\n",
      "|  71 |      71 |  0.997396 |  0.0736873  |      0.993464 |  0.0750692 |\n",
      "|  72 |      72 |  0.99785  |  0.0460651  |      0.993464 |  0.123741  |\n",
      "|  73 |      73 |  0.994269 |  0.0914514  |      0.993464 |  0.14669   |\n",
      "|  74 |      74 |  0.998111 |  0.053059   |      0.993464 |  0.125903  |\n",
      "|  75 |      75 |  0.99785  |  0.0407938  |      0.993464 |  0.0548029 |\n",
      "|  76 |      76 |  0.996612 |  0.044828   |      0.990196 |  0.243427  |\n",
      "|  77 |      77 |  0.996548 |  0.056727   |      0.993464 |  0.0485576 |\n",
      "|  78 |      78 |  0.997199 |  0.0461826  |      0.990196 |  0.144747  |\n",
      "|  79 |      79 |  0.998175 |  0.0365265  |      0.990196 |  0.200507  |\n",
      "|  80 |      80 |  0.996745 |  0.0532171  |      0.996732 |  0.0991592 |\n",
      "|  81 |      81 |  0.997524 |  0.0384981  |      0.993464 |  0.108963  |\n",
      "|  82 |      82 |  0.996286 |  0.055298   |      0.993464 |  0.201488  |\n",
      "|  83 |      83 |  0.996222 |  0.0618946  |      0.993464 |  0.0924729 |\n",
      "|  84 |      84 |  0.996548 |  0.0446289  |      0.996732 |  0.0662689 |\n",
      "|  85 |      85 |  0.999023 |  0.0316445  |      0.993464 |  0.10987   |\n",
      "|  86 |      86 |  0.997786 |  0.0313371  |      0.990196 |  0.135881  |\n",
      "|  87 |      87 |  0.999674 |  0.0193775  |      0.990196 |  0.119576  |\n",
      "|  88 |      88 |  0.997263 |  0.0347466  |      0.993464 |  0.167763  |\n",
      "|  89 |      89 |  0.997524 |  0.0451155  |      0.990196 |  0.128813  |\n",
      "|  90 |      90 |  0.998437 |  0.0282555  |      0.990196 |  0.131283  |\n",
      "|  91 |      91 |  0.999088 |  0.0203068  |      0.993464 |  0.143171  |\n",
      "|  92 |      92 |  0.998437 |  0.0363221  |      0.990196 |  0.221983  |\n",
      "|  93 |      93 |  0.997396 |  0.0503891  |      0.996732 |  0.092702  |\n",
      "|  94 |      94 |  0.991857 |  0.114435   |      0.993464 |  0.118017  |\n",
      "|  95 |      95 |  0.996222 |  0.0597837  |      0.996732 |  0.0302737 |\n",
      "|  96 |      96 |  0.996351 |  0.0755401  |      0.996732 |  0.114603  |\n",
      "|  97 |      97 |  0.997524 |  0.0379895  |      0.993464 |  0.0698755 |\n",
      "|  98 |      98 |  0.996937 |  0.0487928  |      0.990196 |  0.084424  |\n",
      "|  99 |      99 |  0.998698 |  0.0302459  |      0.993464 |  0.0659371 |\n",
      "| 100 |     100 |  0.99746  |  0.0304135  |      0.996732 |  0.0700935 |\n",
      "| 101 |     101 |  0.99785  |  0.0289647  |      0.993464 |  0.107235  |\n",
      "| 102 |     102 |  0.996809 |  0.068625   |      1        |  0.0232075 |\n",
      "| 103 |     103 |  0.998437 |  0.051443   |      0.993464 |  0.094574  |\n",
      "| 104 |     104 |  0.999674 |  0.0156857  |      0.993464 |  0.0980549 |\n",
      "| 105 |     105 |  0.999349 |  0.0229279  |      0.993464 |  0.137493  |\n",
      "| 106 |     106 |  0.999088 |  0.0222024  |      0.993464 |  0.114053  |\n",
      "| 107 |     107 |  1        |  0.0141137  |      0.993464 |  0.0580106 |\n",
      "| 108 |     108 |  0.999674 |  0.0192199  |      0.993464 |  0.0455707 |\n",
      "| 109 |     109 |  1        |  0.0130815  |      0.993464 |  0.0474175 |\n",
      "| 110 |     110 |  0.999023 |  0.0175962  |      0.990196 |  0.160604  |\n",
      "| 111 |     111 |  0.995113 |  0.0656772  |      0.993464 |  0.239083  |\n",
      "| 112 |     112 |  0.998175 |  0.0262344  |      0.993464 |  0.0827826 |\n",
      "| 113 |     113 |  0.999413 |  0.0141999  |      0.993464 |  0.137703  |\n",
      "| 114 |     114 |  0.999088 |  0.0174506  |      0.993464 |  0.209372  |\n",
      "| 115 |     115 |  0.999023 |  0.0202668  |      0.990196 |  0.139552  |\n",
      "| 116 |     116 |  0.998698 |  0.0166084  |      0.990196 |  0.0984938 |\n",
      "| 117 |     117 |  0.999088 |  0.0164621  |      0.990196 |  0.179481  |\n",
      "| 118 |     118 |  0.998762 |  0.0227488  |      0.993464 |  0.163439  |\n",
      "| 119 |     119 |  0.999088 |  0.021385   |      0.993464 |  0.167138  |\n",
      "| 120 |     120 |  0.999023 |  0.0200105  |      0.990196 |  0.0907706 |\n",
      "| 121 |     121 |  0.999349 |  0.0280006  |      0.996732 |  0.0486602 |\n",
      "| 122 |     122 |  0.999674 |  0.0166262  |      0.990196 |  0.103336  |\n",
      "| 123 |     123 |  0.998111 |  0.0337016  |      0.990196 |  0.161432  |\n",
      "| 124 |     124 |  0.99785  |  0.0256642  |      0.990196 |  0.103585  |\n",
      "| 125 |     125 |  0.999088 |  0.0165624  |      0.993464 |  0.073201  |\n",
      "| 126 |     126 |  0.997199 |  0.0296992  |      0.993464 |  0.0458037 |\n",
      "| 127 |     127 |  0.998698 |  0.0248617  |      0.993464 |  0.0816272 |\n",
      "| 128 |     128 |  0.998698 |  0.017829   |      0.993464 |  0.0833836 |\n",
      "| 129 |     129 |  0.999088 |  0.0164804  |      0.993464 |  0.0837333 |\n",
      "| 130 |     130 |  0.999023 |  0.0179342  |      0.990196 |  0.10545   |\n",
      "| 131 |     131 |  0.999674 |  0.00831845 |      0.993464 |  0.090382  |\n",
      "| 132 |     132 |  0.997914 |  0.0281676  |      0.990196 |  0.141103  |\n",
      "| 133 |     133 |  0.998762 |  0.0187505  |      0.993464 |  0.056037  |\n",
      "| 134 |     134 |  0.99746  |  0.0417513  |      0.993464 |  0.065405  |\n",
      "| 135 |     135 |  0.998762 |  0.0186956  |      0.993464 |  0.0803843 |\n",
      "| 136 |     136 |  0.999023 |  0.020791   |      0.996732 |  0.264951  |\n",
      "| 137 |     137 |  0.998698 |  0.0220029  |      0.993464 |  0.110625  |\n",
      "| 138 |     138 |  0.998437 |  0.0239928  |      0.996732 |  0.159813  |\n",
      "| 139 |     139 |  0.99707  |  0.044419   |      0.993464 |  0.189156  |\n",
      "| 140 |     140 |  0.999349 |  0.0177943  |      0.993464 |  0.202362  |\n",
      "| 141 |     141 |  0.998047 |  0.0211628  |      0.993464 |  0.173624  |\n",
      "| 142 |     142 |  0.999674 |  0.0110549  |      0.990196 |  0.153095  |\n",
      "| 143 |     143 |  0.999349 |  0.0110204  |      0.990196 |  0.105867  |\n",
      "| 144 |     144 |  0.998175 |  0.0263974  |      0.993464 |  0.271455  |\n",
      "| 145 |     145 |  0.998437 |  0.0308074  |      0.993464 |  0.132865  |\n",
      "| 146 |     146 |  0.998175 |  0.0171891  |      0.993464 |  0.0656033 |\n",
      "| 147 |     147 |  0.999674 |  0.0121931  |      0.993464 |  0.145023  |\n",
      "| 148 |     148 |  0.999674 |  0.0103877  |      0.990196 |  0.0913124 |\n",
      "| 149 |     149 |  0.998826 |  0.0258462  |      0.996732 |  0.0692702 |\n",
      "| 150 |     150 |  0.998437 |  0.0237923  |      0.990196 |  0.373305  |\n",
      "| 151 |     151 |  0.99746  |  0.0543432  |      0.993464 |  0.16043   |\n",
      "| 152 |     152 |  0.998437 |  0.0286731  |      0.990196 |  0.106745  |\n",
      "| 153 |     153 |  0.999349 |  0.0137888  |      0.990196 |  0.0913332 |\n",
      "| 154 |     154 |  0.999674 |  0.0096099  |      0.993464 |  0.113976  |\n",
      "| 155 |     155 |  0.999023 |  0.0303045  |      0.990196 |  0.162239  |\n",
      "| 156 |     156 |  0.999349 |  0.0125267  |      0.990196 |  0.10138   |\n",
      "| 157 |     157 |  0.99785  |  0.0213165  |      0.996732 |  0.0439903 |\n",
      "| 158 |     158 |  0.998698 |  0.0181312  |      0.990196 |  0.0875705 |\n",
      "| 159 |     159 |  1        |  0.00725429 |      0.990196 |  0.148497  |\n",
      "| 160 |     160 |  0.999413 |  0.00880849 |      0.993464 |  0.123227  |\n",
      "| 161 |     161 |  0.999088 |  0.0195897  |      0.993464 |  0.125883  |\n",
      "| 162 |     162 |  0.99785  |  0.0277421  |      0.993464 |  0.161034  |\n",
      "| 163 |     163 |  0.999674 |  0.0098582  |      0.993464 |  0.0536675 |\n",
      "| 164 |     164 |  0.998762 |  0.0125015  |      0.996732 |  0.0419325 |\n",
      "| 165 |     165 |  0.999674 |  0.0115447  |      0.990196 |  0.0985813 |\n",
      "| 166 |     166 |  1        |  0.00608196 |      0.990196 |  0.126545  |\n",
      "| 167 |     167 |  1        |  0.00728553 |      0.996732 |  0.124356  |\n",
      "| 168 |     168 |  1        |  0.00671491 |      0.993464 |  0.108603  |\n",
      "| 169 |     169 |  0.999349 |  0.0136097  |      0.996732 |  0.107293  |\n",
      "| 170 |     170 |  0.99785  |  0.0283215  |      0.996732 |  0.23499   |\n",
      "| 171 |     171 |  0.998372 |  0.0313399  |      0.990196 |  0.260426  |\n",
      "| 172 |     172 |  0.999023 |  0.0137168  |      0.990196 |  0.229091  |\n",
      "| 173 |     173 |  1        |  0.003515   |      0.990196 |  0.159361  |\n",
      "| 174 |     174 |  0.999413 |  0.00900714 |      0.990196 |  0.184048  |\n",
      "| 175 |     175 |  1        |  0.00432118 |      0.990196 |  0.148017  |\n",
      "| 176 |     176 |  0.999413 |  0.00703969 |      0.993464 |  0.138731  |\n",
      "| 177 |     177 |  0.999674 |  0.00773038 |      0.990196 |  0.107234  |\n",
      "| 178 |     178 |  0.999413 |  0.00934842 |      0.990196 |  0.151799  |\n",
      "| 179 |     179 |  0.998501 |  0.0135588  |      0.993464 |  0.154991  |\n",
      "| 180 |     180 |  0.999349 |  0.0113273  |      0.993464 |  0.130449  |\n",
      "| 181 |     181 |  0.999674 |  0.00990097 |      0.990196 |  0.213046  |\n",
      "| 182 |     182 |  0.999023 |  0.0124212  |      0.990196 |  0.199198  |\n",
      "| 183 |     183 |  0.999413 |  0.00947272 |      0.990196 |  0.257477  |\n",
      "| 184 |     184 |  0.999349 |  0.0110064  |      0.993464 |  0.135232  |\n",
      "| 185 |     185 |  0.999674 |  0.00984794 |      0.990196 |  0.176591  |\n",
      "| 186 |     186 |  0.999674 |  0.0106559  |      0.990196 |  0.213736  |\n",
      "| 187 |     187 |  0.999674 |  0.00884857 |      0.990196 |  0.14279   |\n",
      "| 188 |     188 |  0.999413 |  0.0211696  |      0.993464 |  0.0545168 |\n",
      "| 189 |     189 |  0.995113 |  0.104796   |      0.993464 |  0.46926   |\n",
      "| 190 |     190 |  0.996158 |  0.125585   |      0.990196 |  0.197395  |\n",
      "| 191 |     191 |  0.997524 |  0.0322635  |      0.993464 |  0.216797  |\n",
      "| 192 |     192 |  0.997786 |  0.02702    |      0.993464 |  0.196237  |\n",
      "| 193 |     193 |  0.998111 |  0.0256994  |      0.993464 |  0.175898  |\n",
      "| 194 |     194 |  1        |  0.00465176 |      0.993464 |  0.126671  |\n",
      "| 195 |     195 |  0.999413 |  0.00656672 |      0.996732 |  0.112493  |\n",
      "| 196 |     196 |  0.999413 |  0.0117754  |      0.993464 |  0.126851  |\n",
      "| 197 |     197 |  0.999674 |  0.0102124  |      0.990196 |  0.168733  |\n",
      "| 198 |     198 |  1        |  0.00625948 |      0.993464 |  0.106866  |\n",
      "| 199 |     199 |  0.999674 |  0.0073255  |      0.990196 |  0.147169  |\n"
     ]
    }
   ],
   "source": [
    "#for the training we fit our model and use the batch size and epochs from our constants\n",
    "history = swizzle_model.fit( train_images,\n",
    "                             train_annots,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             epochs=EPOCHS,\n",
    "                             verbose=1,\n",
    "                             use_multiprocessing=True,\n",
    "                             validation_data=(validate_images,validate_annots),\n",
    "                             callbacks=[csv_logger],\n",
    ")\n",
    "\n",
    "swizzle_model_metrics = pd.read_csv('../data/model/metrics_op.csv')\n",
    "print(swizzle_model_metrics.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show plots for our loss function and the accurancy\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Loss', color= '#7900AA')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color = 'c')\n",
    "plt.legend()\n",
    "plt.title('Training - Loss Function')\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "plt.plot(history.history['avg_acc'], label='avg. Accuracy', color = '#7900AA')\n",
    "plt.plot(history.history['val_avg_acc'], label='Validation avg. Accuracy', color = 'c')\n",
    "plt.legend()\n",
    "plt.title('Train - Accuracy')\n",
    "\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "\n",
    "fig.savefig('../data/model/plots_1song_of.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 0.1891\n",
      "Test Accuracy : 0.9934\n"
     ]
    }
   ],
   "source": [
    "#print results of our swizzle model metrics for training\n",
    "score = swizzle_model.evaluate(test_images,test_annots,verbose=0)\n",
    "print('Test Loss : {:.4f}'.format(score[0]))\n",
    "print('Test Accuracy : {:.4f}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 11:47:10.960721: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "#the prediction of our model will show us an array with the strings played in the\n",
    "# belonging frame\n",
    "model_output = swizzle_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision = precision_score(test_annots, model_output, pos_label=\"positive\")\n",
    "#print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 6, 21)\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(127, 6, 21)\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#we can have look on the output arrays. We rounded them to have a better overview. \n",
    "#Thats the first entry with a size of 6 by 21.\n",
    "print(test_annots.shape)\n",
    "print(np.round(test_annots[:1][0],2))\n",
    "print(model_output.shape)\n",
    "print(np.round(model_output[:1][0],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 11:47:11.369233: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../app/model/swizzle_model_1song_of/assets\n",
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "swizzle_model.save('../app/model/swizzle_model_1song_of')\n",
    "\n",
    "loaded_swizzle_model = keras.models.load_model(\"../app/model/swizzle_model_1song_of\", compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the model output\n",
    "np.save(\"../app/model/model_output_1song_of.npy\", model_output, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "#np.load(\"../app/model/model_output.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Try Swizzle-Model out in one Song!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    }
   ],
   "source": [
    "loaded_swizzle_model = keras.models.load_model(\"../app/model/swizzle_model_1song_of\", compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_images_load = np.load('../data/output/00_BN1-129-Eb_solo_mic_data.npz')\n",
    "#f_images = f_images_load['arr_0']\n",
    "#f_true_load = np.load('../data/output/00_BN1-129-Eb_solo_mic_labels.npz')\n",
    "#f_true = f_true_load['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_images = test_images\n",
    "y_true = test_annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_swizzle_model.predict(X_images)\n",
    "y_pred = np.load('../data/output/CNN_PRED_FRONTEND.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 6, 21)\n",
      "<class 'numpy.dtype[float64]'>\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(2827, 6, 21)\n",
      "<class 'numpy.dtype[float64]'>\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "print(y_true.shape)\n",
    "print(type(y_true.dtype))\n",
    "print(y_true[1])\n",
    "print(y_pred.shape)\n",
    "print(type(test_annots.dtype))\n",
    "print(np.round(y_pred[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.load('test_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the list below: 2827 entries\n",
      "1: Frames which are NOT empty!\n",
      "0: Frames which are empty\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    1794\n",
       "0    1033\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for i in y_pred:\n",
    "    corr_i = np.zeros_like(i)\n",
    "    for sidx, string in enumerate(i):\n",
    "        corr_i[sidx][np.argmax(string)] = 1\n",
    "    \n",
    "    x = np.array_equal(test_array, corr_i)\n",
    "    if x == True:\n",
    "        result.append(0)\n",
    "    else:\n",
    "        result.append(1)\n",
    "print('length of the list below:',len(result),'entries')\n",
    "#print(result)\n",
    "df = pd.DataFrame(result)\n",
    "print('1: Frames which are NOT empty!')\n",
    "print('0: Frames which are empty')\n",
    "df.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 6, 21)\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "#__________________________________________________________#\n",
      "(2827, 6, 21)\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score\n",
    "\n",
    "print(y_true.shape)\n",
    "print(y_true[7])\n",
    "print('#__________________________________________________________#')\n",
    "print(y_pred.shape)\n",
    "y_true_ravel = y_true.ravel()\n",
    "\n",
    "# argmax the shizzle out of the swizzle\n",
    "corr_y_pred = np.zeros_like(y_pred)\n",
    "\n",
    "for fidx, frame in enumerate(y_pred):\n",
    "    for sidx, string in enumerate(frame):\n",
    "        corr_y_pred[fidx][sidx][np.argmax(string)] = 1\n",
    "\n",
    "print(corr_y_pred[7])\n",
    "\n",
    "corr_y_pred_ravel = corr_y_pred.ravel()\n",
    "#print(corr_y_pred_ravel[:50])\n",
    "#print(y_true_ravel[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [16002, 356202]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m acc \u001b[39m=\u001b[39m accuracy_score(y_true_ravel, corr_y_pred_ravel)\n\u001b[1;32m      2\u001b[0m prec \u001b[39m=\u001b[39m precision_score(y_true_ravel, corr_y_pred_ravel)\n\u001b[1;32m      3\u001b[0m rec \u001b[39m=\u001b[39m recall_score(y_true_ravel, corr_y_pred_ravel)\n",
      "File \u001b[0;32m~/swizzle/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/swizzle/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m     \u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     85\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred)\n",
      "File \u001b[0;32m~/swizzle/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    330\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    333\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    335\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [16002, 356202]"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_true_ravel, corr_y_pred_ravel)\n",
    "prec = precision_score(y_true_ravel, corr_y_pred_ravel)\n",
    "rec = recall_score(y_true_ravel, corr_y_pred_ravel)\n",
    "f1 = f1_score(y_true_ravel, corr_y_pred_ravel)\n",
    "\n",
    "\n",
    "print('#__________________________________________________________#')\n",
    "print('Accuracy score:', acc)\n",
    "print('#__________________________________________________________#')\n",
    "print('Precision score:', prec)\n",
    "print('#__________________________________________________________#')\n",
    "print('Recall score:', rec)\n",
    "print('#__________________________________________________________#')\n",
    "print('f1_score:', f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data characteristics and Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_characteristics(labels: np.array, verbose: bool = True):\n",
    "    dc = {\n",
    "        'empty_frames': 0,\n",
    "        'single_note_frames': 0,\n",
    "        'multi_note_frames': 0\n",
    "    }\n",
    "\n",
    "    # empty frame\n",
    "    empty = [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.]]\n",
    "\n",
    "    if labels.shape[1:] == (6, 21):\n",
    "\n",
    "        for fidx, frame in enumerate(labels):\n",
    "\n",
    "            if np.all(frame == empty):\n",
    "                dc['empty_frames'] += 1\n",
    "\n",
    "            else:\n",
    "                # get number of notes played by number of strings played\n",
    "                n_notes = 6 - sum([i[0] for i in frame])\n",
    "                if n_notes == 1:\n",
    "                    dc['single_note_frames'] += 1\n",
    "                elif n_notes > 1:\n",
    "                    dc['multi_note_frames'] += 1\n",
    "                else: continue\n",
    "    \n",
    "\n",
    "    if verbose:\n",
    "        print(\"-\"*30)\n",
    "        print(\"|\", \" \"*5, \"Label analysis\", \" \"*5, \"|\")\n",
    "        print(\"-\"*30)\n",
    "\n",
    "        for key, value in dc.items():\n",
    "            if key in ['strings_correct', 'null_correct', 'fully_correct']:\n",
    "                print('-'*30)\n",
    "\n",
    "            print(f\"| {key:<19}: {value:>5} |\")\n",
    "\n",
    "        print(\"-\"*30)\n",
    "    \n",
    "    return dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "|       Label analysis       |\n",
      "------------------------------\n",
      "| empty_frames       :    15 |\n",
      "| single_note_frames :   109 |\n",
      "| multi_note_frames  :     3 |\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "_ = data_characteristics(y_true, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(true: np.array, test: np.array, transform_preds: bool = True, verbose: bool = True):\n",
    "    \"\"\"Takes true labels and (transformed) test labels in the (n, 6, 21) shape and performs error analysis.\n",
    "\n",
    "    Args:\n",
    "        true (np.array): True labels. Shape expected (n, 6, 21)\n",
    "        test (np.array): Test labels. Shape expected (n, 6, 21)\n",
    "        transform_preds (bool): If true, transforms prediction probabilities to 0 or 1 using argmax. Defaults to True.\n",
    "        verbose (bool): If true, prints out results. Defaults to True.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with error analysis data.\n",
    "    \"\"\"\n",
    "\n",
    "    ea = {\n",
    "    'frets_correct': 0,\n",
    "    'frets_wrong': 0,\n",
    "    'strings_correct': 0,\n",
    "    'strings_wrong': 0,\n",
    "    'null_correct': 0,\n",
    "    'null_wrong': 0,\n",
    "    'null_total': 0,\n",
    "    'fully_correct': 0,\n",
    "    'part_correct': 0,\n",
    "    'fully_wrong': 0,\n",
    "    'total': 0\n",
    "}\n",
    "\n",
    "\n",
    "    # transform predictions to be [0, 1]\n",
    "    if transform_preds:\n",
    "        temp = np.zeros_like(test)\n",
    "        for fidx, frame in enumerate(test):\n",
    "            for sidx, string in enumerate(frame):\n",
    "                temp[fidx][sidx][np.argmax(string)] = 1\n",
    "        \n",
    "        test = temp\n",
    "        del temp\n",
    "\n",
    "\n",
    "    # empty frame\n",
    "    empty = [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.]]\n",
    "\n",
    "\n",
    "    # for all frames in true labels\n",
    "    for idx, frame in enumerate(true):\n",
    "\n",
    "        # if no notes were played\n",
    "        if np.all(frame == empty):\n",
    "\n",
    "            if np.all(frame == test[idx]):\n",
    "                ea['null_correct'] += 1\n",
    "            else:\n",
    "                ea['null_wrong'] += 1\n",
    "\n",
    "            ea['null_total'] += 1\n",
    "\n",
    "        # if a note was played\n",
    "        else:\n",
    "            # strings match\n",
    "            if np.all(frame[:, 0] == test[idx][:, 0]):\n",
    "                ea['strings_correct'] += 1\n",
    "            \n",
    "            else: \n",
    "                ea['strings_wrong'] += 1\n",
    "\n",
    "            # frets match\n",
    "            if np.all(frame[:, 1:] == test[idx][:, 1:]):\n",
    "                ea['frets_correct'] += 1\n",
    "            \n",
    "            # only some of the frets match\n",
    "            elif np.any(frame[:, 1:] == test[idx][:, 1:]):\n",
    "                ea['part_correct'] += 1\n",
    "                ea['frets_wrong'] += 1\n",
    "\n",
    "            # no frets match\n",
    "            elif not np.any(frame[:, 1:] == test[idx][:, 1:]):\n",
    "                ea['frets_wrong'] += 1\n",
    "\n",
    "            # nothing matches\n",
    "            if not np.any(frame == test[idx]):\n",
    "                ea['fully_wrong'] += 1\n",
    "            \n",
    "            # everything matches\n",
    "            if np.all(frame == test[idx]):\n",
    "                ea['fully_correct'] += 1\n",
    "        \n",
    "        # increase frame counter\n",
    "        ea['total'] += 1\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"-\"*26)\n",
    "        print(\"|\", \" \"*3, \"Error analysis\", \" \"*3, \"|\")\n",
    "        print(\"-\"*26)\n",
    "\n",
    "        for key, value in ea.items():\n",
    "            if key in ['strings_correct', 'null_correct', 'fully_correct']:\n",
    "                print('-'*26)\n",
    "\n",
    "            print(f\"| {key:<15}: {value:>5} |\")\n",
    "\n",
    "        print(\"-\"*26)\n",
    "    \n",
    "    return ea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "|     Error analysis     |\n",
      "--------------------------\n",
      "| frets_correct  :     1 |\n",
      "| frets_wrong    :   111 |\n",
      "--------------------------\n",
      "| strings_correct:    18 |\n",
      "| strings_wrong  :    94 |\n",
      "--------------------------\n",
      "| null_correct   :     2 |\n",
      "| null_wrong     :    13 |\n",
      "| null_total     :    15 |\n",
      "--------------------------\n",
      "| fully_correct  :     1 |\n",
      "| part_correct   :   111 |\n",
      "| fully_wrong    :     0 |\n",
      "| total          :   127 |\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "errors = error_analysis(y_true, y_pred, transform_preds=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total percentage of right predicted values of all values: 2.3622047244094486\n",
      "Percentage of right predicted strings out of strings: 16.07142857142857\n",
      "Percentage of right predicted frets out of frets: 0.8928571428571428\n"
     ]
    }
   ],
   "source": [
    "#total percentage of total values\n",
    "a = errors['total']/100\n",
    "t = (errors['fully_correct']+errors['null_correct'])/a\n",
    "print('Total percentage of right predicted values of all values:',t)\n",
    "\n",
    "#strings percentage of all strings\n",
    "strings = errors['strings_correct']+errors['strings_wrong']\n",
    "b = strings/100\n",
    "s = errors['strings_correct']/b\n",
    "print('Percentage of right predicted strings out of strings:',s)\n",
    "#fret percentage of all frets\n",
    "strings = errors['frets_correct']+errors['frets_wrong']\n",
    "c = strings/100\n",
    "f = errors['frets_correct']/c\n",
    "print('Percentage of right predicted frets out of frets:',f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ce22ec9b47a0c8818982fc2e83d14df8db5ffc759b38b6aa7930ef673c52175"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
