{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __CNN__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to use CNN(convolutional neural networks) for the task of guitar tablature estimation. The previous work of Andrew Wiggins and Youngmoo Kim showed that CNNs have shown promise for translating guitar audios to tabs, and the use of CNNs has also been explored for various other tasks within music information retrieval such as musical tempo estimation, key classification, singing voice detection, and instrument classification. It is proven that CNN is a powerful tool for the purpose of our study."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Import libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages \n",
    "\n",
    "#various\n",
    "import datetime\n",
    "import pathlib\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import warnings\n",
    "\n",
    "\n",
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "\n",
    "#keras\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "RSEED = 42\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Tensorflow version\n",
    "print(tf.__version__)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Define Input Shapes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "FRAME_HEIGHT = 192\n",
    "FRAME_WIDTH = 9\n",
    "N_CLASSES = 21\n",
    "N_STRINGS = 6\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_PATH = '../app/model/'\n",
    "INPUT_PATH = '../data/output/'\n",
    "\n",
    "# Model is saved under the following path and name:\n",
    "model_name = BASE_PATH + 'swizzle_model'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Load Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "images = np.load(INPUT_PATH + 'training_data_solo_0.npz')\n",
    "annots = np.load(INPUT_PATH + 'training_labels_solo_0.npz')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Do train & test split__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we have to split our dataset into train and test set. We use 70% for the train set and 30% for the test set.\n",
    "train_images, test_images, train_annots, test_annots = train_test_split(images['arr_0'], annots['arr_0'], test_size= 0.2, shuffle=True, random_state= RSEED )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because we need also a validation set we split once more. We take this time 10% of the train set for \n",
    "#the validation set and take the rest for training.\n",
    "train_images, validate_images,train_annots,validate_annots = train_test_split(train_images, train_annots, test_size = 0.1, shuffle=True, random_state = RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's have a look on the different shapes of our sets\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(validate_images.shape)\n",
    "print(train_annots.shape)\n",
    "print(test_annots.shape)\n",
    "print(validate_annots.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Define our softmax function by string__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_by_string(t):\n",
    "        sh = K.shape(t)\n",
    "        string_sm = []\n",
    "        for i in range(N_STRINGS):\n",
    "            string_sm.append(K.expand_dims(K.softmax(t[:,i,:]), axis=1))\n",
    "        return K.concatenate(string_sm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catcross_by_string(target, output):\n",
    "        loss = 0\n",
    "        for i in range(N_STRINGS):\n",
    "            loss += K.categorical_crossentropy(target[:,i,:], output[:,i,:])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_acc(y_true, y_pred):\n",
    "        return K.mean(K.equal(K.argmax(y_true, axis=-1), K.argmax(y_pred, axis=-1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Building our CNN Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function of our cnn model\n",
    "def cnn_swizzle_model():       \n",
    "        \"\"\"The swizzleCNN.\n",
    "        \n",
    "        what it takes:\n",
    "        - a picture with a certain frame height(192 px) and a frame width(9 px)\n",
    "        - only one color channel, therefore as a grayscale image\n",
    "\n",
    "        what it returns:\n",
    "\n",
    "        An array with the size 6x21. This is representing the 6 different strings of a guitar and 19 different \n",
    "        frets of the guitar. The other 2 of the 21 entries represent, if a string is played or not played.\n",
    "\n",
    "        The different layers we used you can easily extract from below.\n",
    "\n",
    "        Returns:\n",
    "            Keras Sequential: The swizzleCNN architecture.\n",
    "        \"\"\"\n",
    "        swizzle_model = tf.keras.Sequential()\n",
    "        swizzle_model.add(tf.keras.layers.InputLayer(input_shape=[FRAME_HEIGHT, FRAME_WIDTH, 1]))\n",
    "        swizzle_model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3),activation='relu'))\n",
    "        swizzle_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "        swizzle_model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "        swizzle_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "        swizzle_model.add(tf.keras.layers.Dropout(0.25))   \n",
    "        swizzle_model.add(tf.keras.layers.Flatten())\n",
    "        swizzle_model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "        swizzle_model.add(tf.keras.layers.Dropout(0.5))\n",
    "        swizzle_model.add(tf.keras.layers.Dense(N_CLASSES * N_STRINGS))\n",
    "        swizzle_model.add(tf.keras.layers.Reshape((N_STRINGS, N_CLASSES)))\n",
    "        swizzle_model.add(tf.keras.layers.Activation(softmax_by_string))\n",
    "        return swizzle_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the swizzleCNN\n",
    "swizzle_model = cnn_swizzle_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look on the model summary to see the different layers and their shapes\n",
    "# we have 3 dimensions in the beginning, then flatten to 1 Dimension for the dense layers and after them\n",
    "# create the end shape representing the guitar with 6 strings and 21 frets\n",
    "swizzle_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model metrics for the cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Metric: For our model we will use the average accuracy metric, because we want to have a good overall \n",
    "prediction by our model. Besides that, for us every tone has the same importance so all classes\n",
    "have the same importance.\n",
    "\n",
    "Optimizer: As an optimizer we take the adadelta optimizer, which is fast enough to handle our data \n",
    "in a short time.\n",
    "\n",
    "Loss function: For the loss function we used categorical crossentropy by string because we have multiple classes or labels\n",
    "with soft probabilities like [0.5, 0.3, 0.2].\n",
    "'''\n",
    "\n",
    "metrics = avg_acc\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adadelta(learning_rate=1.0)\n",
    "\n",
    "swizzle_model.compile(loss=catcross_by_string, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Train CNN__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for model \n",
    "'''This function takes the path of a new folder and create a new one. \n",
    "If the folder already exists, it will pass.'''\n",
    "def my_makedirs(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "my_makedirs('../app/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics are logged using\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('../app/model/metrics_' + model_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the training we fit our model and use the batch size and epochs from our constants\n",
    "history = swizzle_model.fit( train_images,\n",
    "                             train_annots,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             epochs=EPOCHS,\n",
    "                             verbose=1,\n",
    "                             use_multiprocessing=True,\n",
    "                             validation_data=(validate_images,validate_annots),\n",
    "                             callbacks=[csv_logger]\n",
    ")\n",
    "\n",
    "swizzle_model_metrics = pd.read_csv('../app/model/metrics_' + model_name + '.csv')\n",
    "print(swizzle_model_metrics.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show plots for our loss function and the accurancy\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Loss', color= '#7900AA')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss', color = 'c')\n",
    "plt.legend()\n",
    "plt.title('Training - Loss Function')\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "plt.plot(history.history['avg_acc'], label='avg. Accuracy', color = '#7900AA')\n",
    "plt.plot(history.history['val_avg_acc'], label='Validation avg. Accuracy', color = 'c')\n",
    "plt.legend()\n",
    "plt.title('Train - Accuracy')\n",
    "\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "\n",
    "fig.savefig('../data/model/plots_' + model_name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print results of our swizzle model metrics for training\n",
    "score = swizzle_model.evaluate(test_images,test_annots,verbose=0)\n",
    "print('Test Loss : {:.4f}'.format(score[0]))\n",
    "print('Test Accuracy : {:.4f}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model\n",
    "swizzle_model.save(model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the previously saved model\n",
    "loaded_swizzle_model = keras.models.load_model(model_name, compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "X_images = test_images\n",
    "y_true = test_annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = loaded_swizzle_model.predict(X_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model predictions\n",
    "np.save(model_name, y_pred, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shapes of truth and prediction (have to match!)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print(y_true.shape)\n",
    "print(type(y_true.dtype))\n",
    "print(y_true[0])\n",
    "print(y_pred.shape)\n",
    "print(type(test_annots.dtype))\n",
    "print(np.round(y_pred[0]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.load('test_array.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for i in y_pred:\n",
    "    corr_i = np.zeros_like(i)\n",
    "    for sidx, string in enumerate(i):\n",
    "        corr_i[sidx][np.argmax(string)] = 1\n",
    "    \n",
    "    x = np.array_equal(test_array, corr_i)\n",
    "    if x == True:\n",
    "        result.append(0)\n",
    "    else:\n",
    "        result.append(1)\n",
    "print('length of the list below:',len(result),'entries')\n",
    "#print(result)\n",
    "df = pd.DataFrame(result)\n",
    "print('1: Frames which are NOT empty!')\n",
    "print('0: Frames which are empty')\n",
    "df.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score\n",
    "\n",
    "print(y_true.shape)\n",
    "print(y_true[20])\n",
    "print('#__________________________________________________________#')\n",
    "print(y_pred.shape)\n",
    "y_true_ravel = y_true.ravel()\n",
    "\n",
    "# argmax the shizzle out of the swizzle\n",
    "corr_y_pred = np.zeros_like(y_pred)\n",
    "\n",
    "for fidx, frame in enumerate(y_pred):\n",
    "    for sidx, string in enumerate(frame):\n",
    "        corr_y_pred[fidx][sidx][np.argmax(string)] = 1\n",
    "\n",
    "print(corr_y_pred[20])\n",
    "\n",
    "corr_y_pred_ravel = corr_y_pred.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true_ravel, corr_y_pred_ravel)\n",
    "prec = precision_score(y_true_ravel, corr_y_pred_ravel)\n",
    "rec = recall_score(y_true_ravel, corr_y_pred_ravel)\n",
    "f1 = f1_score(y_true_ravel, corr_y_pred_ravel)\n",
    "\n",
    "\n",
    "print('#__________________________________________________________#')\n",
    "print('Accuracy score:', acc)\n",
    "print('#__________________________________________________________#')\n",
    "print('Precision score:', prec)\n",
    "print('#__________________________________________________________#')\n",
    "print('Recall score:', rec)\n",
    "print('#__________________________________________________________#')\n",
    "print('f1_score:', f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data characteristics and Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_characteristics(labels: np.array, verbose: bool = True):\n",
    "    dc = {\n",
    "        'empty_frames': 0,\n",
    "        'single_note_frames': 0,\n",
    "        'multi_note_frames': 0\n",
    "    }\n",
    "\n",
    "    # empty frame\n",
    "    empty = [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.]]\n",
    "\n",
    "    if labels.shape[1:] == (6, 21):\n",
    "\n",
    "        for fidx, frame in enumerate(labels):\n",
    "\n",
    "            if np.all(frame == empty):\n",
    "                dc['empty_frames'] += 1\n",
    "\n",
    "            else:\n",
    "                # get number of notes played by number of strings played\n",
    "                n_notes = 6 - sum([i[0] for i in frame])\n",
    "                if n_notes == 1:\n",
    "                    dc['single_note_frames'] += 1\n",
    "                elif n_notes > 1:\n",
    "                    dc['multi_note_frames'] += 1\n",
    "                else: continue\n",
    "    \n",
    "\n",
    "    if verbose:\n",
    "        print(\"-\"*30)\n",
    "        print(\"|\", \" \"*5, \"Label analysis\", \" \"*5, \"|\")\n",
    "        print(\"-\"*30)\n",
    "\n",
    "        for key, value in dc.items():\n",
    "            if key in ['strings_correct', 'null_correct', 'fully_correct']:\n",
    "                print('-'*30)\n",
    "\n",
    "            print(f\"| {key:<19}: {value:>5} |\")\n",
    "\n",
    "        print(\"-\"*30)\n",
    "    \n",
    "    return dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = data_characteristics(y_true, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(true: np.array, test: np.array, transform_preds: bool = True, verbose: bool = True):\n",
    "    \"\"\"Takes true labels and (transformed) test labels in the (n, 6, 21) shape and performs error analysis.\n",
    "\n",
    "    Args:\n",
    "        true (np.array): True labels. Shape expected (n, 6, 21)\n",
    "        test (np.array): Test labels. Shape expected (n, 6, 21)\n",
    "        transform_preds (bool): If true, transforms prediction probabilities to 0 or 1 using argmax. Defaults to True.\n",
    "        verbose (bool): If true, prints out results. Defaults to True.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with error analysis data.\n",
    "    \"\"\"\n",
    "\n",
    "    ea = {\n",
    "    'frets_correct': 0,\n",
    "    'frets_wrong': 0,\n",
    "    'strings_correct': 0,\n",
    "    'strings_wrong': 0,\n",
    "    'null_correct': 0,\n",
    "    'null_wrong': 0,\n",
    "    'null_total': 0,\n",
    "    'fully_correct': 0,\n",
    "    'part_correct': 0,\n",
    "    'fully_wrong': 0,\n",
    "    'total': 0\n",
    "}\n",
    "\n",
    "\n",
    "    # transform predictions to be [0, 1]\n",
    "    if transform_preds:\n",
    "        temp = np.zeros_like(test)\n",
    "        for fidx, frame in enumerate(test):\n",
    "            for sidx, string in enumerate(frame):\n",
    "                temp[fidx][sidx][np.argmax(string)] = 1\n",
    "        \n",
    "        test = temp\n",
    "        del temp\n",
    "\n",
    "\n",
    "    # empty frame\n",
    "    empty = [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.],\n",
    "             [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.]]\n",
    "\n",
    "\n",
    "    # for all frames in true labels\n",
    "    for idx, frame in enumerate(true):\n",
    "\n",
    "        # if no notes were played\n",
    "        if np.all(frame == empty):\n",
    "\n",
    "            if np.all(frame == test[idx]):\n",
    "                ea['null_correct'] += 1\n",
    "            else:\n",
    "                ea['null_wrong'] += 1\n",
    "\n",
    "            ea['null_total'] += 1\n",
    "\n",
    "        # if a note was played\n",
    "        else:\n",
    "            # strings match\n",
    "            if np.all(frame[:, 0] == test[idx][:, 0]):\n",
    "                ea['strings_correct'] += 1\n",
    "            \n",
    "            else: \n",
    "                ea['strings_wrong'] += 1\n",
    "\n",
    "            # frets match\n",
    "            if np.all(frame[:, 1:] == test[idx][:, 1:]):\n",
    "                ea['frets_correct'] += 1\n",
    "            \n",
    "            # only some of the frets match\n",
    "            elif np.any(frame[:, 1:] == test[idx][:, 1:]):\n",
    "                ea['part_correct'] += 1\n",
    "                ea['frets_wrong'] += 1\n",
    "\n",
    "            # no frets match\n",
    "            elif not np.any(frame[:, 1:] == test[idx][:, 1:]):\n",
    "                ea['frets_wrong'] += 1\n",
    "\n",
    "            # nothing matches\n",
    "            if not np.any(frame == test[idx]):\n",
    "                ea['fully_wrong'] += 1\n",
    "            \n",
    "            # everything matches\n",
    "            if np.all(frame == test[idx]):\n",
    "                ea['fully_correct'] += 1\n",
    "        \n",
    "        # increase frame counter\n",
    "        ea['total'] += 1\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"-\"*26)\n",
    "        print(\"|\", \" \"*3, \"Error analysis\", \" \"*3, \"|\")\n",
    "        print(\"-\"*26)\n",
    "\n",
    "        for key, value in ea.items():\n",
    "            if key in ['strings_correct', 'null_correct', 'fully_correct']:\n",
    "                print('-'*26)\n",
    "\n",
    "            print(f\"| {key:<15}: {value:>5} |\")\n",
    "\n",
    "        print(\"-\"*26)\n",
    "    \n",
    "    return ea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = error_analysis(y_true, y_pred, transform_preds=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total percentage of total values\n",
    "a = errors['total']/100\n",
    "t = (errors['fully_correct']+errors['null_correct'])/a\n",
    "print('Total percentage of right predicted values of all values:',t)\n",
    "\n",
    "#strings percentage of all strings\n",
    "strings = errors['strings_correct']+errors['strings_wrong']\n",
    "b = strings/100\n",
    "s = errors['strings_correct']/b\n",
    "print('Percentage of right predicted strings out of strings:',s)\n",
    "#fret percentage of all frets\n",
    "strings = errors['frets_correct']+errors['frets_wrong']\n",
    "c = strings/100\n",
    "f = errors['frets_correct']/c\n",
    "print('Percentage of right predicted frets out of frets:',f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ce22ec9b47a0c8818982fc2e83d14df8db5ffc759b38b6aa7930ef673c52175"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
